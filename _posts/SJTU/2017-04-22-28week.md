---
layout: post
title: SJTU 第28周
description: ""
category: 生活
tags: []
---

> 这一周我看了一些关于目标函数的基础知识:范数 矩阵求导 梯度下降 冷启动问题

- 批量梯度下降
  - 每次迭代对所有的样本进行计算（全局最优，耗时）
- 随机梯度下降
  - 单词迭代只计算一个样本（可能不是全局最优）

1. 矩阵的特征值 特征向量 （只针对方阵）
2. 矩阵的奇异值分解 （提取矩阵的主要信息，左奇异值，特征值，右奇异值）

1. L0范数是指向量中非0的元素的个数
2. L1范数是指向量中各个元素绝对值之和，也有个美称叫“稀疏规则算子”（Lasso regularization）
3. L1范数和L0范数可以实现稀疏，L1因具有比L0更好的优化求解特性而被广泛应用。
4. 参数稀疏有什么好处呢  特征选择(Feature Selection) 可解释性(Interpretability)
5. L2 范数，在回归里面，有人把有它的回归叫“岭回归”（Ridge Regression），有人也叫它“权值衰减weight decay”
6. L2范数是指向量各元素的平方和然后求平方根
7. L2范数的好处是什么呢？这里也扯上两点
   - 从学习理论的角度来说，L2范数可以防止过拟合，提升模型的泛化能力
   - 从优化或者数值计算的角度来说，L2范数有助于处理 condition number不好的情况下矩阵求逆很困难的问题
   - 对condition number来个一句话总结：conditionnumber是一个矩阵（或者它所描述的线性系统）的稳定性或者敏感度的度量，如果一个矩阵的condition number在1附近，那么它就是well-conditioned的，如果远大于1，那么它就是ill-conditioned的，如果一个系统是ill-conditioned的，它的输出结果就不要太相信了
